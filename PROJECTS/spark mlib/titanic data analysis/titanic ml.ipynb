{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/user/spark-3.0.0-bin-hadoop2.7')\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "spark = SparkSession.Builder().master('local').appName('titanic').getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = spark.read.csv('/home/user/PROJECTS luminar/spark mlib/titanic.csv',\n",
    "                              inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "891\n",
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_data.show()\n",
    "print(titanic_data.count())\n",
    "titanic_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PassengerId', 'int'), ('Survived', 'int'), ('Pclass', 'int'), ('Name', 'string'), ('Sex', 'string'), ('Age', 'double'), ('SibSp', 'int'), ('Parch', 'int'), ('Ticket', 'string'), ('Fare', 'double'), ('Cabin', 'string'), ('Embarked', 'string')]\n",
      "PassengerId=-0.005006660767066522\n",
      "Survived=1.0\n",
      "Pclass=-0.33848103596101514\n",
      "Age=0.010539215871285685\n",
      "SibSp=-0.03532249888573558\n",
      "Parch=0.08162940708348336\n",
      "Fare=0.2573065223849626\n"
     ]
    }
   ],
   "source": [
    "# titanic_data_pandas=titanic_data.toPandas()\n",
    "# to find the correlation between different columns (Non string) in dataframe with respect to Survived Column\n",
    "\n",
    "# print(titanic_data.select('Age').dtypes[0][1])\n",
    "print(titanic_data.dtypes)\n",
    "for c in titanic_data.columns:\n",
    "    if titanic_data.select(c).dtypes[0][1] != 'string':\n",
    "        print(c + '=' + str(titanic_data.stat.corr(c, 'Survived')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId 0\n",
      "Survived 0\n",
      "Pclass 0\n",
      "Name 0\n",
      "Sex 0\n",
      "Age 177\n",
      "SibSp 0\n",
      "Parch 0\n",
      "Ticket 0\n",
      "Fare 0\n",
      "Cabin 687\n",
      "Embarked 2\n"
     ]
    }
   ],
   "source": [
    "# To find the null value count in each column\n",
    "for c in titanic_data.columns:\n",
    "    print(c, titanic_data.filter(col(c).isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Embarked='S', count=644)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.groupBy('Embarked').count().orderBy('count', ascending=False).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode S\n"
     ]
    }
   ],
   "source": [
    "# To find the mode of embarked column\n",
    "\n",
    "mode_embarked=titanic_data.groupBy('Embarked').count().orderBy('count', ascending=False).first()[0]\n",
    "\n",
    "# print('mode ' , titanic_data.select('Embarked').collect())\n",
    "\n",
    "print('mode', mode_embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId 0\n",
      "Survived 0\n",
      "Pclass 0\n",
      "Name 0\n",
      "Sex 0\n",
      "Age 177\n",
      "SibSp 0\n",
      "Parch 0\n",
      "Ticket 0\n",
      "Fare 0\n",
      "Cabin 687\n",
      "Embarked 2\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "# To fill embarked column with mode of Embarked Column\n",
    "# titanic_data = titanic_data.fillna(mode_embarked, subset=['Embarked'])\n",
    "\n",
    "\n",
    "for c in titanic_data.columns:\n",
    "    print(c, titanic_data.filter(col(c).isNull()).count())\n",
    "\n",
    "\n",
    "age_mean = titanic_data.select(mean('Age')).first()[0]\n",
    "# age_mean.show()\n",
    "print(int(age_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId 0\n",
      "Survived 0\n",
      "Pclass 0\n",
      "Name 0\n",
      "Sex 0\n",
      "Age 0\n",
      "SibSp 0\n",
      "Parch 0\n",
      "Ticket 0\n",
      "Fare 0\n",
      "Cabin 687\n",
      "Embarked 0\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|29.0|    0|    0|          330877| 8.4583|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|29.0|    0|    0|          244373|   13.0|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|29.0|    0|    0|            2649|  7.225|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# titanic_data = titanic_data.fillna(int(age_mean), subset=['Age'])\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "titanic_data = titanic_data.fillna({'Age':int(age_mean) , 'Embarked':mode_embarked})\n",
    "#\n",
    "for c in titanic_data.columns:\n",
    "    print(c, titanic_data.filter(col(c).isNull()).count())\n",
    "#\n",
    "titanic_data = titanic_data.drop('Cabin')\n",
    "titanic_data.show()\n",
    "#\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_extract(name):\n",
    "    return re.findall(r'( [A-Za-z]+)\\.',name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|    Title|count|\n",
      "+---------+-----+\n",
      "|   Master|   40|\n",
      "|      Rev|    6|\n",
      "|     Capt|    1|\n",
      "|      Mrs|  125|\n",
      "|     Miss|  182|\n",
      "|     Lady|    1|\n",
      "| Jonkheer|    1|\n",
      "|       Mr|  517|\n",
      "|      Sir|    1|\n",
      "|      Col|    2|\n",
      "| Countess|    1|\n",
      "|     Mlle|    2|\n",
      "|       Dr|    7|\n",
      "|    Major|    2|\n",
      "|      Don|    1|\n",
      "|       Ms|    1|\n",
      "|      Mme|    1|\n",
      "+---------+-----+\n",
      "\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|  Title|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|     Mr|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|    Mrs|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|   Miss|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|       S|    Mrs|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|       S|     Mr|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|29.0|    0|    0|          330877| 8.4583|       Q|     Mr|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|       S|     Mr|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|       S| Master|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|       S|    Mrs|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|       C|    Mrs|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|       S|   Miss|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55|       S|   Miss|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05|       S|     Mr|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275|       S|     Mr|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|       S|   Miss|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0|       S|    Mrs|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|       Q| Master|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|29.0|    0|    0|          244373|   13.0|       S|     Mr|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|       S|    Mrs|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|29.0|    0|    0|            2649|  7.225|       C|    Mrs|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#\n",
    "title_extract_udf = udf(title_extract)\n",
    "titanic_data = titanic_data.withColumn('Title', title_extract_udf('Name'))\n",
    "titanic_data.groupBy('Title').count().show()\n",
    "titanic_data.show()\n",
    "# # # rare = titanic_data.groupBy('Title').count().filter(col('count')<8).select('Title').collect()\n",
    "# # # rare = [x[0] for x in rare]\n",
    "# # # print(rare)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stringI = StringIndexer(inputCol='Sex',outputCol='Sex_Index')\n",
    "# model = stringI.fit(titanic_data)\n",
    "# indexed_df = model.transform(titanic_data)\n",
    "\n",
    "\n",
    "# indexed_df.show()\n",
    "def string_index_fun(col_name):\n",
    "    stringIndexer = StringIndexer(inputCol=col_name, outputCol=col_name+'_Index')\n",
    "    model = stringIndexer.fit(titanic_data)\n",
    "    indexed = model.transform(titanic_data)\n",
    "\n",
    "    encoder = OneHotEncoder(inputCol=col_name+'_Index', outputCol=col_name+'_Vector')\n",
    "    encode_model = encoder.fit(indexed)\n",
    "    encoded = encode_model.transform(indexed)\n",
    "\n",
    "    return encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexables = ['Embarked','Sex','Title']\n",
    "for i in indexables:\n",
    "    titanic_data=string_index_fun(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+--------------+---------------+---------+-------------+-----------+--------------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|  Title|Embarked_Index|Embarked_Vector|Sex_Index|   Sex_Vector|Title_Index|  Title_Vector|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+--------------+---------------+---------+-------------+-----------+--------------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|     Mr|           0.0|  (2,[0],[1.0])|      0.0|(1,[0],[1.0])|        0.0|(16,[0],[1.0])|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|    Mrs|           1.0|  (2,[1],[1.0])|      1.0|    (1,[],[])|        2.0|(16,[2],[1.0])|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|   Miss|           0.0|  (2,[0],[1.0])|      1.0|    (1,[],[])|        1.0|(16,[1],[1.0])|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|       S|    Mrs|           0.0|  (2,[0],[1.0])|      1.0|    (1,[],[])|        2.0|(16,[2],[1.0])|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|       S|     Mr|           0.0|  (2,[0],[1.0])|      0.0|(1,[0],[1.0])|        0.0|(16,[0],[1.0])|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|29.0|    0|    0|          330877| 8.4583|       Q|     Mr|           2.0|      (2,[],[])|      0.0|(1,[0],[1.0])|        0.0|(16,[0],[1.0])|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|       S|     Mr|           0.0|  (2,[0],[1.0])|      0.0|(1,[0],[1.0])|        0.0|(16,[0],[1.0])|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|       S| Master|           0.0|  (2,[0],[1.0])|      0.0|(1,[0],[1.0])|        3.0|(16,[3],[1.0])|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|       S|    Mrs|           0.0|  (2,[0],[1.0])|      1.0|    (1,[],[])|        2.0|(16,[2],[1.0])|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|       C|    Mrs|           1.0|  (2,[1],[1.0])|      1.0|    (1,[],[])|        2.0|(16,[2],[1.0])|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|       S|   Miss|           0.0|  (2,[0],[1.0])|      1.0|    (1,[],[])|        1.0|(16,[1],[1.0])|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55|       S|   Miss|           0.0|  (2,[0],[1.0])|      1.0|    (1,[],[])|        1.0|(16,[1],[1.0])|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05|       S|     Mr|           0.0|  (2,[0],[1.0])|      0.0|(1,[0],[1.0])|        0.0|(16,[0],[1.0])|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275|       S|     Mr|           0.0|  (2,[0],[1.0])|      0.0|(1,[0],[1.0])|        0.0|(16,[0],[1.0])|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|       S|   Miss|           0.0|  (2,[0],[1.0])|      1.0|    (1,[],[])|        1.0|(16,[1],[1.0])|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0|       S|    Mrs|           0.0|  (2,[0],[1.0])|      1.0|    (1,[],[])|        2.0|(16,[2],[1.0])|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|       Q| Master|           2.0|      (2,[],[])|      0.0|(1,[0],[1.0])|        3.0|(16,[3],[1.0])|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|29.0|    0|    0|          244373|   13.0|       S|     Mr|           0.0|  (2,[0],[1.0])|      0.0|(1,[0],[1.0])|        0.0|(16,[0],[1.0])|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|       S|    Mrs|           0.0|  (2,[0],[1.0])|      1.0|    (1,[],[])|        2.0|(16,[2],[1.0])|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|29.0|    0|    0|            2649|  7.225|       C|    Mrs|           1.0|  (2,[1],[1.0])|      1.0|    (1,[],[])|        2.0|(16,[2],[1.0])|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+--------------+---------------+---------+-------------+-----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "titanic_data = titanic_data.drop('PassengerId','Title','Embarked','Name','Ticket','Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+-------+--------------+---------------+---------+-------------+-----------+--------------+\n",
      "|Survived|Pclass| Age|SibSp|Parch|   Fare|Embarked_Index|Embarked_Vector|Sex_Index|   Sex_Vector|Title_Index|  Title_Vector|\n",
      "+--------+------+----+-----+-----+-------+--------------+---------------+---------+-------------+-----------+--------------+\n",
      "|       0|     3|22.0|    1|    0|   7.25|           0.0|  (2,[0],[1.0])|      0.0|(1,[0],[1.0])|        0.0|(16,[0],[1.0])|\n",
      "|       1|     1|38.0|    1|    0|71.2833|           1.0|  (2,[1],[1.0])|      1.0|    (1,[],[])|        2.0|(16,[2],[1.0])|\n",
      "|       1|     3|26.0|    0|    0|  7.925|           0.0|  (2,[0],[1.0])|      1.0|    (1,[],[])|        1.0|(16,[1],[1.0])|\n",
      "|       1|     1|35.0|    1|    0|   53.1|           0.0|  (2,[0],[1.0])|      1.0|    (1,[],[])|        2.0|(16,[2],[1.0])|\n",
      "|       0|     3|35.0|    0|    0|   8.05|           0.0|  (2,[0],[1.0])|      0.0|(1,[0],[1.0])|        0.0|(16,[0],[1.0])|\n",
      "|       0|     3|29.0|    0|    0| 8.4583|           2.0|      (2,[],[])|      0.0|(1,[0],[1.0])|        0.0|(16,[0],[1.0])|\n",
      "|       0|     1|54.0|    0|    0|51.8625|           0.0|  (2,[0],[1.0])|      0.0|(1,[0],[1.0])|        0.0|(16,[0],[1.0])|\n",
      "|       0|     3| 2.0|    3|    1| 21.075|           0.0|  (2,[0],[1.0])|      0.0|(1,[0],[1.0])|        3.0|(16,[3],[1.0])|\n",
      "|       1|     3|27.0|    0|    2|11.1333|           0.0|  (2,[0],[1.0])|      1.0|    (1,[],[])|        2.0|(16,[2],[1.0])|\n",
      "|       1|     2|14.0|    1|    0|30.0708|           1.0|  (2,[1],[1.0])|      1.0|    (1,[],[])|        2.0|(16,[2],[1.0])|\n",
      "|       1|     3| 4.0|    1|    1|   16.7|           0.0|  (2,[0],[1.0])|      1.0|    (1,[],[])|        1.0|(16,[1],[1.0])|\n",
      "|       1|     1|58.0|    0|    0|  26.55|           0.0|  (2,[0],[1.0])|      1.0|    (1,[],[])|        1.0|(16,[1],[1.0])|\n",
      "|       0|     3|20.0|    0|    0|   8.05|           0.0|  (2,[0],[1.0])|      0.0|(1,[0],[1.0])|        0.0|(16,[0],[1.0])|\n",
      "|       0|     3|39.0|    1|    5| 31.275|           0.0|  (2,[0],[1.0])|      0.0|(1,[0],[1.0])|        0.0|(16,[0],[1.0])|\n",
      "|       0|     3|14.0|    0|    0| 7.8542|           0.0|  (2,[0],[1.0])|      1.0|    (1,[],[])|        1.0|(16,[1],[1.0])|\n",
      "|       1|     2|55.0|    0|    0|   16.0|           0.0|  (2,[0],[1.0])|      1.0|    (1,[],[])|        2.0|(16,[2],[1.0])|\n",
      "|       0|     3| 2.0|    4|    1| 29.125|           2.0|      (2,[],[])|      0.0|(1,[0],[1.0])|        3.0|(16,[3],[1.0])|\n",
      "|       1|     2|29.0|    0|    0|   13.0|           0.0|  (2,[0],[1.0])|      0.0|(1,[0],[1.0])|        0.0|(16,[0],[1.0])|\n",
      "|       0|     3|31.0|    1|    0|   18.0|           0.0|  (2,[0],[1.0])|      1.0|    (1,[],[])|        2.0|(16,[2],[1.0])|\n",
      "|       1|     3|29.0|    0|    0|  7.225|           1.0|  (2,[1],[1.0])|      1.0|    (1,[],[])|        2.0|(16,[2],[1.0])|\n",
      "+--------+------+----+-----+-----+-------+--------------+---------------+---------+-------------+-----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+-------+---------------+-------------+--------------+\n",
      "|Survived|Pclass| Age|SibSp|Parch|   Fare|Embarked_Vector|   Sex_Vector|  Title_Vector|\n",
      "+--------+------+----+-----+-----+-------+---------------+-------------+--------------+\n",
      "|       0|     3|22.0|    1|    0|   7.25|  (2,[0],[1.0])|(1,[0],[1.0])|(16,[0],[1.0])|\n",
      "|       1|     1|38.0|    1|    0|71.2833|  (2,[1],[1.0])|    (1,[],[])|(16,[2],[1.0])|\n",
      "|       1|     3|26.0|    0|    0|  7.925|  (2,[0],[1.0])|    (1,[],[])|(16,[1],[1.0])|\n",
      "|       1|     1|35.0|    1|    0|   53.1|  (2,[0],[1.0])|    (1,[],[])|(16,[2],[1.0])|\n",
      "|       0|     3|35.0|    0|    0|   8.05|  (2,[0],[1.0])|(1,[0],[1.0])|(16,[0],[1.0])|\n",
      "|       0|     3|29.0|    0|    0| 8.4583|      (2,[],[])|(1,[0],[1.0])|(16,[0],[1.0])|\n",
      "|       0|     1|54.0|    0|    0|51.8625|  (2,[0],[1.0])|(1,[0],[1.0])|(16,[0],[1.0])|\n",
      "|       0|     3| 2.0|    3|    1| 21.075|  (2,[0],[1.0])|(1,[0],[1.0])|(16,[3],[1.0])|\n",
      "|       1|     3|27.0|    0|    2|11.1333|  (2,[0],[1.0])|    (1,[],[])|(16,[2],[1.0])|\n",
      "|       1|     2|14.0|    1|    0|30.0708|  (2,[1],[1.0])|    (1,[],[])|(16,[2],[1.0])|\n",
      "|       1|     3| 4.0|    1|    1|   16.7|  (2,[0],[1.0])|    (1,[],[])|(16,[1],[1.0])|\n",
      "|       1|     1|58.0|    0|    0|  26.55|  (2,[0],[1.0])|    (1,[],[])|(16,[1],[1.0])|\n",
      "|       0|     3|20.0|    0|    0|   8.05|  (2,[0],[1.0])|(1,[0],[1.0])|(16,[0],[1.0])|\n",
      "|       0|     3|39.0|    1|    5| 31.275|  (2,[0],[1.0])|(1,[0],[1.0])|(16,[0],[1.0])|\n",
      "|       0|     3|14.0|    0|    0| 7.8542|  (2,[0],[1.0])|    (1,[],[])|(16,[1],[1.0])|\n",
      "|       1|     2|55.0|    0|    0|   16.0|  (2,[0],[1.0])|    (1,[],[])|(16,[2],[1.0])|\n",
      "|       0|     3| 2.0|    4|    1| 29.125|      (2,[],[])|(1,[0],[1.0])|(16,[3],[1.0])|\n",
      "|       1|     2|29.0|    0|    0|   13.0|  (2,[0],[1.0])|(1,[0],[1.0])|(16,[0],[1.0])|\n",
      "|       0|     3|31.0|    1|    0|   18.0|  (2,[0],[1.0])|    (1,[],[])|(16,[2],[1.0])|\n",
      "|       1|     3|29.0|    0|    0|  7.225|  (2,[1],[1.0])|    (1,[],[])|(16,[2],[1.0])|\n",
      "+--------+------+----+-----+-----+-------+---------------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_data=titanic_data.drop(*[c for c in titanic_data.columns if c.endswith('Index')])\n",
    "titanic_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = titanic_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_Vector', 'Sex_Vector', 'Title_Vector']\n"
     ]
    }
   ],
   "source": [
    "input_cols.remove('Survived')\n",
    "print(input_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization\n",
    "assembler = VectorAssembler(inputCols=input_cols,outputCol='features')\n",
    "titanic_data = assembler.transform(titanic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+-------+---------------+-------------+--------------+------------------------------------------------------------+\n",
      "|Survived|Pclass|Age |SibSp|Parch|Fare   |Embarked_Vector|Sex_Vector   |Title_Vector  |features                                                    |\n",
      "+--------+------+----+-----+-----+-------+---------------+-------------+--------------+------------------------------------------------------------+\n",
      "|0       |3     |22.0|1    |0    |7.25   |(2,[0],[1.0])  |(1,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,2,4,5,7,8],[3.0,22.0,1.0,7.25,1.0,1.0,1.0])        |\n",
      "|1       |1     |38.0|1    |0    |71.2833|(2,[1],[1.0])  |(1,[],[])    |(16,[2],[1.0])|(24,[0,1,2,4,6,10],[1.0,38.0,1.0,71.2833,1.0,1.0])          |\n",
      "|1       |3     |26.0|0    |0    |7.925  |(2,[0],[1.0])  |(1,[],[])    |(16,[1],[1.0])|(24,[0,1,4,5,9],[3.0,26.0,7.925,1.0,1.0])                   |\n",
      "|1       |1     |35.0|1    |0    |53.1   |(2,[0],[1.0])  |(1,[],[])    |(16,[2],[1.0])|(24,[0,1,2,4,5,10],[1.0,35.0,1.0,53.1,1.0,1.0])             |\n",
      "|0       |3     |35.0|0    |0    |8.05   |(2,[0],[1.0])  |(1,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,4,5,7,8],[3.0,35.0,8.05,1.0,1.0,1.0])              |\n",
      "|0       |3     |29.0|0    |0    |8.4583 |(2,[],[])      |(1,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,4,7,8],[3.0,29.0,8.4583,1.0,1.0])                  |\n",
      "|0       |1     |54.0|0    |0    |51.8625|(2,[0],[1.0])  |(1,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,4,5,7,8],[1.0,54.0,51.8625,1.0,1.0,1.0])           |\n",
      "|0       |3     |2.0 |3    |1    |21.075 |(2,[0],[1.0])  |(1,[0],[1.0])|(16,[3],[1.0])|(24,[0,1,2,3,4,5,7,11],[3.0,2.0,3.0,1.0,21.075,1.0,1.0,1.0])|\n",
      "|1       |3     |27.0|0    |2    |11.1333|(2,[0],[1.0])  |(1,[],[])    |(16,[2],[1.0])|(24,[0,1,3,4,5,10],[3.0,27.0,2.0,11.1333,1.0,1.0])          |\n",
      "|1       |2     |14.0|1    |0    |30.0708|(2,[1],[1.0])  |(1,[],[])    |(16,[2],[1.0])|(24,[0,1,2,4,6,10],[2.0,14.0,1.0,30.0708,1.0,1.0])          |\n",
      "|1       |3     |4.0 |1    |1    |16.7   |(2,[0],[1.0])  |(1,[],[])    |(16,[1],[1.0])|(24,[0,1,2,3,4,5,9],[3.0,4.0,1.0,1.0,16.7,1.0,1.0])         |\n",
      "|1       |1     |58.0|0    |0    |26.55  |(2,[0],[1.0])  |(1,[],[])    |(16,[1],[1.0])|(24,[0,1,4,5,9],[1.0,58.0,26.55,1.0,1.0])                   |\n",
      "|0       |3     |20.0|0    |0    |8.05   |(2,[0],[1.0])  |(1,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,4,5,7,8],[3.0,20.0,8.05,1.0,1.0,1.0])              |\n",
      "|0       |3     |39.0|1    |5    |31.275 |(2,[0],[1.0])  |(1,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,2,3,4,5,7,8],[3.0,39.0,1.0,5.0,31.275,1.0,1.0,1.0])|\n",
      "|0       |3     |14.0|0    |0    |7.8542 |(2,[0],[1.0])  |(1,[],[])    |(16,[1],[1.0])|(24,[0,1,4,5,9],[3.0,14.0,7.8542,1.0,1.0])                  |\n",
      "|1       |2     |55.0|0    |0    |16.0   |(2,[0],[1.0])  |(1,[],[])    |(16,[2],[1.0])|(24,[0,1,4,5,10],[2.0,55.0,16.0,1.0,1.0])                   |\n",
      "|0       |3     |2.0 |4    |1    |29.125 |(2,[],[])      |(1,[0],[1.0])|(16,[3],[1.0])|(24,[0,1,2,3,4,7,11],[3.0,2.0,4.0,1.0,29.125,1.0,1.0])      |\n",
      "|1       |2     |29.0|0    |0    |13.0   |(2,[0],[1.0])  |(1,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,4,5,7,8],[2.0,29.0,13.0,1.0,1.0,1.0])              |\n",
      "|0       |3     |31.0|1    |0    |18.0   |(2,[0],[1.0])  |(1,[],[])    |(16,[2],[1.0])|(24,[0,1,2,4,5,10],[3.0,31.0,1.0,18.0,1.0,1.0])             |\n",
      "|1       |3     |29.0|0    |0    |7.225  |(2,[1],[1.0])  |(1,[],[])    |(16,[2],[1.0])|(24,[0,1,4,6,10],[3.0,29.0,7.225,1.0,1.0])                  |\n",
      "+--------+------+----+-----+-----+-------+---------------+-------------+--------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_data.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731 160\n"
     ]
    }
   ],
   "source": [
    "#spliting\n",
    "train,test = titanic_data.randomSplit([0.8,0.2],seed=1)\n",
    "print(train.count(),test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------Logistic Regression________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('-'*40 + 'Logistic Regression' +'_'*40)\n",
    "\n",
    "lr = LogisticRegression(labelCol='Survived', featuresCol='features')\n",
    "lrmodel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|Survived|prediction|\n",
      "+--------+----------+\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict_train=model.transform(train)\n",
    "predict_test=lrmodel.transform(test)\n",
    "predict_test.select(\"Survived\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+-------+---------------+-------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "|Survived|Pclass| Age|SibSp|Parch|   Fare|Embarked_Vector|   Sex_Vector|   Title_Vector|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+------+----+-----+-----+-------+---------------+-------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "|       0|     1|21.0|    0|    1|77.2875|  (2,[0],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,3,4,5,7,...|[0.34160648894338...|[0.58458070545014...|       0.0|\n",
      "|       0|     1|29.0|    0|    0|    0.0|  (2,[0],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,5,7,8],[...|[0.29852675065698...|[0.57408232932709...|       0.0|\n",
      "|       0|     1|29.0|    0|    0| 25.925|  (2,[0],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,4,5,7,8]...|[0.25927191364233...|[0.56445730363394...|       0.0|\n",
      "|       0|     1|29.0|    0|    0|   26.0|  (2,[0],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,4,5,7,8]...|[0.25915835095088...|[0.56442938458065...|       0.0|\n",
      "|       0|     1|29.0|    0|    0|27.7208|  (2,[1],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,4,6,7,8]...|[-0.2303128620551...|[0.44267495661887...|       1.0|\n",
      "|       0|     1|29.0|    1|    0|   66.6|  (2,[0],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,2,4,5,7,...|[0.72802025044531...|[0.67437067991196...|       0.0|\n",
      "|       0|     1|31.0|    1|    0|   52.0|  (2,[0],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,2,4,5,7,...|[0.80917473646167...|[0.69193361776898...|       0.0|\n",
      "|       0|     1|33.0|    0|    0|    5.0|  (2,[0],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,4,5,7,8]...|[0.40905113538397...|[0.60086033710499...|       0.0|\n",
      "|       0|     1|40.0|    0|    0|27.7208|  (2,[1],[1.0])|(1,[0],[1.0])|(16,[11],[1.0])|(24,[0,1,4,6,7,19...|[-13.280515329735...|[1.70743717937383...|       1.0|\n",
      "|       0|     1|44.0|    2|    0|   90.0|      (2,[],[])|(1,[0],[1.0])| (16,[4],[1.0])|(24,[0,1,2,4,7,12...|[0.07344743150432...|[0.51835360786779...|       0.0|\n",
      "|       0|     1|47.0|    0|    0|25.5875|  (2,[0],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,4,5,7,8]...|[0.79121148446334...|[0.68809140057735...|       0.0|\n",
      "|       0|     1|47.0|    0|    0|   52.0|  (2,[0],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,4,5,7,8]...|[0.75121848995422...|[0.67944414404962...|       0.0|\n",
      "|       0|     1|50.0|    1|    0|106.425|  (2,[1],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,2,4,6,7,...|[0.80085279249458...|[0.69015687215131...|       0.0|\n",
      "|       0|     1|56.0|    0|    0|30.6958|  (2,[1],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,4,6,7,8]...|[0.56232529258107...|[0.63699039721647...|       0.0|\n",
      "|       0|     1|64.0|    1|    4|  263.0|  (2,[0],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,2,3,4,5,...|[3.04915689939302...|[0.95474611349806...|       0.0|\n",
      "|       0|     1|65.0|    0|    0|  26.55|  (2,[0],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,4,5,7,8]...|[1.32118263529906...|[0.78937839892622...|       0.0|\n",
      "|       0|     2|18.0|    0|    0|   11.5|  (2,[0],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,4,5,7,8]...|[1.09925308185059...|[0.75012012947306...|       0.0|\n",
      "|       0|     2|18.0|    0|    0|   13.0|  (2,[0],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,4,5,7,8]...|[1.09698182802139...|[0.74969416403311...|       0.0|\n",
      "|       0|     2|19.0|    1|    1|  36.75|  (2,[0],[1.0])|(1,[0],[1.0])| (16,[0],[1.0])|(24,[0,1,2,3,4,5,...|[2.01717784005438...|[0.88258887629593...|       0.0|\n",
      "|       0|     2|23.0|    0|    0|   10.5|  (2,[0],[1.0])|(1,[0],[1.0])| (16,[4],[1.0])|(24,[0,1,4,5,7,12...|[0.36740264652988...|[0.59083121749151...|       0.0|\n",
      "+--------+------+----+-----+-----+-------+---------------+-------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predict_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = predict_test.filter((col('Survived')==0) & (col('prediction')==0)).count()\n",
    "tn = predict_test.filter((col('Survived')==1) & (col('prediction')==1)).count()\n",
    "fp = predict_test.filter((col('Survived')==1) & (col('prediction')==0)).count()\n",
    "fn = predict_test.filter((col('Survived')==0) & (col('prediction')==1)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[89. 15.]\n",
      " [14. 42.]]\n",
      "89 14 15 42\n",
      "-------------------------------------------------------\n",
      "acc = 0.81875\n"
     ]
    }
   ],
   "source": [
    "# prediction , Label , float()\n",
    "preds_and_labels = predict_test.select(['prediction','Survived']).withColumn('label', col('Survived').cast(FloatType())).orderBy('prediction')\n",
    "metrics = MulticlassMetrics(preds_and_labels.select('prediction','label').rdd.map(tuple))\n",
    "\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(tp,fp,fn,tn)\n",
    "\n",
    "print('-'*55)\n",
    "\n",
    "print('acc = '+ str((tp+tn)/(tp+tn+fp+fn)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.18125 \n",
      "0.81875\n",
      "[-1.142901161984344,-0.029523807706080152,-0.5303371698047312,-0.3962965534844821,0.0015141692194655138,-0.7113519015308525,-0.22448627091765708,-29.352086684280955,-13.374964352447638,-39.70100103191786,-38.81545671047,-9.864754400540312,-12.493980709377064,-47.99363901626195,-12.510364404113853,-12.543917071426865,197.06562465690737,-35.98322226901333,230.45751339367908,0.0,-49.16671077012835,240.39826442604013,210.04799658027727,174.3739639562326] 45.13896777306313\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predict_test)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "print(accuracy)\n",
    "# print(tp/(tp+fp))\n",
    "# #\n",
    "#\n",
    "print(lrmodel.coefficients , lrmodel.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------Decision Tree________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('-'*40 + 'Decision Tree' + '_'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|Survived|prediction|\n",
      "+--------+----------+\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol='Survived', featuresCol='features')\n",
    "dtmodel = dt.fit(train)\n",
    "# predict_train=model.transform(train)\n",
    "predict_testdt=dtmodel.transform(test)\n",
    "predict_testdt .select(\"Survived\",\"prediction\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 18 15 38\n",
      "acc = 0.79375\n"
     ]
    }
   ],
   "source": [
    "tp = predict_testdt.filter((col('Survived')==0) & (col('prediction')==0)).count()\n",
    "tn = predict_testdt.filter((col('Survived')==1) & (col('prediction')==1)).count()\n",
    "fp = predict_testdt.filter((col('Survived')==1) & (col('prediction')==0)).count()\n",
    "fn = predict_testdt.filter((col('Survived')==0) & (col('prediction')==1)).count()\n",
    "print(tp,fp,fn,tn)\n",
    "\n",
    "print('acc = '+ str((tp+tn)/(tp+tn+fp+fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.20625 \n",
      "----------------------------------------Random Forest________________________________________\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluator.evaluate(predict_testdt)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "\n",
    "\n",
    "print('-'*40 + 'Random Forest' + '_'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|Survived|prediction|\n",
      "+--------+----------+\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol='Survived', featuresCol='features')\n",
    "rfmodel = rf.fit(train)\n",
    "# predict_train=model.transform(train)\n",
    "predict_testrf=rfmodel.transform(test)\n",
    "predict_testrf.select(\"Survived\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 16 16 40\n",
      "acc = 0.8\n",
      "Test Error = 0.20625 \n"
     ]
    }
   ],
   "source": [
    "tp = predict_testrf.filter((col('Survived')==0) & (col('prediction')==0)).count()\n",
    "tn = predict_testrf.filter((col('Survived')==1) & (col('prediction')==1)).count()\n",
    "fp = predict_testrf.filter((col('Survived')==1) & (col('prediction')==0)).count()\n",
    "fn = predict_testrf.filter((col('Survived')==0) & (col('prediction')==1)).count()\n",
    "print(tp,fp,fn,tn)\n",
    "\n",
    "print('acc = '+ str((tp+tn)/(tp+tn+fp+fn)))\n",
    "\n",
    "\n",
    "accuracy = evaluator.evaluate(predict_testdt)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
